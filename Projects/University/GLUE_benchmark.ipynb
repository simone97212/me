{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai\n",
        "\n",
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-[...]\"\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "LEGEND_MODEL_ID = \"ft:gpt-4o-2024-08-06:sesar-lab:gpt-tuned-legend:Cae1R16c\"\n",
        "REG_MODEL_ID    = \"ft:gpt-4o-2024-08-06:sesar-lab:gpt-tuned-reg:CaeYGbam\"\n",
        "\n",
        "#Nomi file di valutazione\n",
        "SCENARIO_FILE = \"gender_eval_scenario.jsonl\"\n",
        "BIAS_FILE     = \"gender_eval_bias.jsonl\"\n",
        "STANCE_FILE   = \"gender_eval_stance.jsonl\"\n",
        "\n",
        "print(\"Setup completato\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUEEc9KVG4kZ",
        "outputId": "ff655ba6-639a-4516-8cd9-582479b6be6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completato. Client inizializzato.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_eval_rows(path):\n",
        "    #Carica le righe JSONL e restituisce una lista di liste di messages\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            obj = json.loads(line)\n",
        "            rows.append(obj[\"messages\"])\n",
        "    return rows\n",
        "\n",
        "def gold_label(messages):\n",
        "    #L'ultima entry (assistant) nel JSONL è la gold label.\n",
        "    return messages[-1][\"content\"].strip()\n",
        "\n",
        "def call_model(model_id, messages, temperature=0.0):\n",
        "    #Chiamata al modello OpenAI/FineTuneDB\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_id,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=50,\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "def norm_simple(text):\n",
        "    return text.lower().strip().replace(\".\", \"\")\n",
        "\n",
        "def norm_scenario(text):\n",
        "    t = norm_simple(text)\n",
        "    # accetta variazioni leggere\n",
        "    if \"non\" in t and \"compliant\" in t:\n",
        "        return \"non-compliant\"\n",
        "    if \"not compliant\" in t:\n",
        "        return \"non-compliant\"\n",
        "    if \"compliant\" in t or \"yes\" in t:\n",
        "        return \"compliant\"\n",
        "    # fallback: prima parola\n",
        "    return t.split()[0] if t else t\n",
        "\n",
        "def norm_bias(text):\n",
        "    t = norm_simple(text)\n",
        "    if \"biased\" in t:\n",
        "        return \"biased\"\n",
        "    if \"unbiased\" in t or \"no bias\" in t:\n",
        "        return \"unbiased\"\n",
        "    return t.split()[0] if t else t\n",
        "\n",
        "def norm_stance(text):\n",
        "    t = norm_simple(text)\n",
        "    if \"support\" in t or \"pro \" in t or \"in favour\" in t:\n",
        "        return \"supportive\"\n",
        "    if \"against\" in t or \"oppose\" in t or \"contrary\" in t:\n",
        "        return \"against\"\n",
        "    if \"neutral\" in t or \"no strong opinion\" in t:\n",
        "        return \"neutral\"\n",
        "    # se la risposta è solo l'etichetta va già bene\n",
        "    return t.split()[0] if t else t\n",
        "\n",
        "def accuracy(model_id, rows, normalizer_gold, normalizer_pred, verbose=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, msgs in enumerate(rows):\n",
        "        gold = normalizer_gold(gold_label(msgs))\n",
        "        pred_raw = call_model(model_id, msgs[:-1])  # senza gold label\n",
        "        pred = normalizer_pred(pred_raw)\n",
        "\n",
        "        #debug it -> se True\n",
        "        if verbose:\n",
        "            print(f\"\\nEsempio {i+1}\")\n",
        "            print(\"Gold:\", gold)\n",
        "            print(\"Pred:\", pred_raw, \"->\", pred)\n",
        "\n",
        "        if pred == gold:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    return correct / total if total > 0 else 0.0\n"
      ],
      "metadata": {
        "id": "6Z58jFJaNPh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scenario_rows = load_eval_rows(SCENARIO_FILE)\n",
        "bias_rows     = load_eval_rows(BIAS_FILE)\n",
        "stance_rows   = load_eval_rows(STANCE_FILE)\n",
        "\n",
        "print(\"ScenarioEval esempi:\", len(scenario_rows))\n",
        "print(\"BiasDetect esempi:\", len(bias_rows))\n",
        "print(\"Stance esempi:\", len(stance_rows))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA4kfQ3zNT_R",
        "outputId": "8301e0e1-0179-4729-f210-5a8f313a55b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ScenarioEval esempi: 10\n",
            "BiasDetect esempi: 10\n",
            "Stance esempi: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "print(\"Valutazione Legend_tuned...\")\n",
        "results[\"Legend_tuned\"] = {\n",
        "    \"ScenarioEval_acc\": accuracy(LEGEND_MODEL_ID, scenario_rows,\n",
        "                                 normalizer_gold=norm_scenario,\n",
        "                                 normalizer_pred=norm_scenario),\n",
        "    \"BiasDetect_acc\":   accuracy(LEGEND_MODEL_ID, bias_rows,\n",
        "                                 normalizer_gold=norm_bias,\n",
        "                                 normalizer_pred=norm_bias),\n",
        "    \"Stance_acc\":       accuracy(LEGEND_MODEL_ID, stance_rows,\n",
        "                                 normalizer_gold=norm_stance,\n",
        "                                 normalizer_pred=norm_stance),\n",
        "}\n",
        "\n",
        "print(\"Valutazione Reg_tuned...\")\n",
        "results[\"Reg_tuned\"] = {\n",
        "    \"ScenarioEval_acc\": accuracy(REG_MODEL_ID, scenario_rows,\n",
        "                                 normalizer_gold=norm_scenario,\n",
        "                                 normalizer_pred=norm_scenario),\n",
        "    \"BiasDetect_acc\":   accuracy(REG_MODEL_ID, bias_rows,\n",
        "                                 normalizer_gold=norm_bias,\n",
        "                                 normalizer_pred=norm_bias),\n",
        "    \"Stance_acc\":       accuracy(REG_MODEL_ID, stance_rows,\n",
        "                                 normalizer_gold=norm_stance,\n",
        "                                 normalizer_pred=norm_stance),\n",
        "}\n",
        "\n",
        "print(\"\\n=== RISULTATI GENDERGLUE ===\")\n",
        "for model_name, scores in results.items():\n",
        "    print(model_name)\n",
        "    for task, acc in scores.items():\n",
        "        print(f\"  {task}: {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5N65rSYNXY9",
        "outputId": "3b4da7cf-a58a-491e-a2fe-d603dcdafba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valutazione Legend_tuned...\n",
            "Valutazione Reg_tuned...\n",
            "\n",
            "=== RISULTATI GENDERGLUE ===\n",
            "Legend_tuned\n",
            "  ScenarioEval_acc: 0.000\n",
            "  BiasDetect_acc: 0.400\n",
            "  Stance_acc: 0.900\n",
            "Reg_tuned\n",
            "  ScenarioEval_acc: 0.500\n",
            "  BiasDetect_acc: 0.100\n",
            "  Stance_acc: 1.000\n"
          ]
        }
      ]
    }
  ]
}
